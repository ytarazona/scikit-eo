{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c23e4b1",
   "metadata": {},
   "source": [
    "# A Python package for Remote Sensing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d9c5b",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Nowadays, remotely sensed data has increased dramatically. Microwaves and optical images with different spatial and temporal resolutions are available and are using to monitor a variaty of environmental issues such as deforestation [@Tarazona2018], [@Tarazona2021], land degradation, crop classifications, among other . Although there are efforts (i.e., python packages, forums, communities, etc.) to make available line-of-code tools for pre-processing, processing and analysis of satellite imagery, there is still a gap that needs to be filled. In other words, too much time is still spent by many users in developing Python lines of code. Algorithms for mapping land degradation through linear trend of vegetation indices (Tarazona and Miyasiro, 2020), fusion optical and radar images to classify vegetation cover, calibration of machine learning lagorithms, among others, are not available yet.\n",
    "\n",
    "Therefore, **scikit-eo** is a Python package that provides tools for remote sensing. This package was developed to fill the gaps in remotely sensed data processing tools. Most of the tools are based on scientific publications, and others are useful algorithms that will allow processing to be done in a few lines of code. With these tools, the user will be able to invest time in analyzing the results of their data and not spend time on elaborating lines of code, which can sometimes be stressful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080d0073",
   "metadata": {},
   "source": [
    "# Highlights\n",
    "\n",
    "Through Object-Oriented Programming and Structured Programming, **scikit-eo** provides a useful variety of remote sensing tools. For instance, something basic but essential in the land cover characterization mapping with artificial intelligence thecniques (machine learning or deep learning) is to obtain together the confusion matrix and metrics such as user's accuracy, producer's accuracy, omissions and commissions. This metrics combination can be obtained with **scikit-eo** on a pandas ```DataFrame``` object. On the other hand, a predicted classes map, i.e., a land cover map which represents the output of the classification algorithm (machine learning) or the output of the segmentation algorithm (deep learning), must be accompanied by its uncertainties with a confidence interval ($95$% or $90$%), and additionally, any metric obtained from the confusion matrix must be represented with a confidence level as well. All these metrics can be obtained with **scikit-eo**. Other useful tools for remote sensing can be found in this python package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639453ff",
   "metadata": {},
   "source": [
    "# Audience\n",
    "\n",
    "**scikit-eo** is intended for students, professionals, researchers, and organizations involved in satellite images processing and analysis. **scikit-eo** can be used for university teaching, lectures, research and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484f3f7",
   "metadata": {},
   "source": [
    "# Funtionalities\n",
    "\n",
    "\n",
    "## Main tools\n",
    "\n",
    "**Scikit-eo** comes with several algorithms to process satelitte images in order to study different environmental issues. Atmospheric correction, machine learning and deep learning, estimating area and uncertainty, linear trend, combining optical and radar images, among others, are some main functions listed below:\n",
    "\n",
    "| Name of functions  | Description|\n",
    "| -------------------| --------------------------------------------------------------------------|\n",
    "| **`mla`**          | Supervised Classification in Remote Sensing                               |\n",
    "| **`calmla`**       | Calibrating Supervised Classification in Remote Sensing                   |\n",
    "| **`confintervalML`**       | Information of Confusion Matrix by proportions of area, overall accuracy, user's accuracy with confidence interval and estimated area with confidence interval as well.                         |\n",
    "| **`deepLearning`** | Deep Learning algorithms                                                  |\n",
    "| **`atmosCorr`**    | Radiometric and Atmospheric Correction                              |\n",
    "| **`rkmeans`**      | K-means classification                                                    |\n",
    "| **`calkmeans`**    | This function allows to calibrate the kmeans algorithm. It is possible to obtain the best k value and the best embedded algorithm in kmeans.                               |\n",
    "| **`pca`**          | Principal Components Analysis                                             |\n",
    "| **`linearTrend`**  | Linear trend is useful for mapping forest degradation or land degradation |\n",
    "| **`fusionrs`**     | This algorithm allows to fusion images coming from different spectral sensors (e.g., optical-optical, optical and SAR or SAR-SAR). Among many of the qualities of this function, it is possible to obtain the contribution (%) of each variable in the fused image |\n",
    "| **`sma`**          | Spectral Mixture Analysis - Classification sup-pixel                      |\n",
    "| **`tassCap`**      | The Tasseled-Cap Transformation                                           |\n",
    "\n",
    ": Main tools available for **scikit-eo** package. \\label{table:1}\n",
    "\n",
    "Of course, some others functions Will be found in the package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db879e",
   "metadata": {},
   "source": [
    "## Applications with brief examples\n",
    "\n",
    "### Example 01\n",
    "\n",
    "An example of ML will be obtain. For this, Landsat-8 OLI (Operational Land Imager) will be used to classify using the Random Forest (RF) classifier. The datasets to be used in these examples can be downloaded [here](https://drive.google.com/drive/folders/193RhNpACu9THcOZu8OzMh-btnFCOgHrU?usp=sharing):\n",
    "\n",
    "```python\n",
    "# 01. Libraries to used in these examples\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from dbfread import DBF\n",
    "from scikeo.mla import MLA\n",
    "from scikeo.fusionrs import fusionrs\n",
    "from scikeo.calmla import calmla\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# 02. Image and endmembers\n",
    "path_raster = r\"C:\\data\\ml\\LC08_232066_20190727_SR.tif\"\n",
    "img = rasterio.open(path_raster)\n",
    "\n",
    "path_endm = r\"C:\\data\\ml\\endmembers.dbf\"\n",
    "endm = DBF(path_endm)\n",
    "\n",
    "# 03. Instance of mla()\n",
    "inst = MLA(image = img, endmembers = endm)\n",
    "\n",
    "# 04. Applying RF with 70% of data to train\n",
    "rf_class = inst.RF(training_split = 0.7)\n",
    "```\n",
    "\n",
    "Classification results:\n",
    "\n",
    "![Original image and Image classified in the left and right panel respectively. \\label{fig:AIM}](scikit_eo_00.png){ width=50% }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf056fc",
   "metadata": {},
   "source": [
    "### Example 02\n",
    "\n",
    "On the other hand, calibration methods [@Tarazona2021] such as Leave One Out Cross-Validation (LOOCV), Cross-Validation (CV) and Monte Carlos Cross-Validation (MCCV) are embedded in this python package. \n",
    "In this second example, MCCV will be used in order to calibrate a supervised classification with different algorithms.\n",
    "\n",
    "```python\n",
    "# 01. Endmembers\n",
    "path_endm = r\"C:\\data\\ml\\endmembers.dbf\"\n",
    "endm = DBF(path_endm)\n",
    "\n",
    "# 02. Instance of calmla()\n",
    "inst = calmla(endmembers = endm)\n",
    "\n",
    "# 03. Applying the splitData() method\n",
    "data = inst.splitData()\n",
    "```\n",
    "\n",
    "**Calibrating with *Monte Carlo Cross-Validation Calibration* (MCCV)**\n",
    "\n",
    "**Parameters**:\n",
    "- ```split_data```: A instance obtaind with ```splitData()```\n",
    "- ```models```: Support Vector Machine (svm), Decision Tree (dt), Random Forest (rf) and Naive Bayes (nb)\n",
    "- ```n_iter```: Number of iterations\n",
    "\n",
    "```python\n",
    "# 04. Running MCCV\n",
    "error_mccv = inst.MCCV(split_data = data, models = ('svm', 'dt', 'rf', 'nb'), n_iter = 10)\n",
    "```\n",
    "\n",
    "Calibration results:\n",
    "\n",
    "\n",
    "![Original image and Image classified in the left and right panel respectively. \\label{fig:AIM}](scikit_eo_01.png){ width=50% }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4025b",
   "metadata": {},
   "source": [
    "### Example 03\n",
    "\n",
    "In this example we cover the topic of fusion of images with different observation geometry and that record information in different ranges of the electromagnetic spectrum (Tarazona et al., 2021). The fusion of radar and optical images, although well used to improve land cover mapping, has so far not been developed tools to discuss the contributions of both images in data fusion. In ```scikit-eo``` we developed the function ```fusionrs()``` which provides us with a dictionary with the following image fusion interpretation features:\n",
    "\n",
    "- *Fused_images*: The fusion of both images into a 3d array\n",
    "- *Variance*: The variance obtained\n",
    "- *Proportion_of_variance*: The proportion of the obtained variance\n",
    "- *Cumulative_variance*: The cumulative variance\n",
    "- *Correlation*: Correlation of the original bands with the principal components\n",
    "- *Contributions_in_%*: The contributions of each optical and radar band in the fusion\n",
    "\n",
    "```python\n",
    "# 01 \n",
    "path_optical = r\"C:\\data\\ml\\LC08_003069_20180906.tif\"\n",
    "optical = rasterio.open(path_optical)\n",
    "\n",
    "path_radar = r\"C:\\data\\ml\\S1_2018_VV_VH.tif\"\n",
    "radar = rasterio.open(path_radar)\n",
    "\n",
    "# 02 Applying the fusionrs:\n",
    "fusion = fusionrs(optical = optical, radar = radar)\n",
    "\n",
    "# 03 Dictionary of results:\n",
    "fusion.keys()\n",
    "\n",
    "# 04 Proportion of variance:\n",
    "prop_var = fusion.get('Proportion_of_variance')\n",
    "\n",
    "# 05 Cumulative variance (%):\n",
    "cum_var = fusion.get('Cumulative_variance')*100\n",
    "\n",
    "# 06 Showing the proportion of variance and cumulative:\n",
    "x_labels = ['PC{}'.format(i+1) for i in range(len(prop_var))]\n",
    "\n",
    "fig, axes = plt.subplots(figsize = (6,5))\n",
    "ln1 = axes.plot(x_labels, prop_var, marker ='o', markersize = 6,  label = 'Proportion of variance')\n",
    "\n",
    "axes2 = axes.twinx()\n",
    "ln2 = axes2.plot(x_labels, cum_var, marker = 'o', color = 'r', label = \"Cumulative variance\")\n",
    "\n",
    "ln = ln1 + ln2\n",
    "labs = [l.get_label() for l in ln]\n",
    "\n",
    "axes.legend(ln, labs, loc = 'center right')\n",
    "axes.set_xlabel(\"Principal Component\")\n",
    "axes.set_ylabel(\"Proportion of Variance\")\n",
    "axes2.set_ylabel(\"Cumulative (%)\")\n",
    "axes2.grid(False)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![Proportion of Variance and acumulative. \\label{fig:AIM}](scikit_eo_02.png){ width=50% }\n",
    "\n",
    "```python\n",
    "# 07 Contributions of each variable in %:\n",
    "fusion.get('Contributions_in_%')\n",
    "```\n",
    "\n",
    "![Contributions. \\label{fig:AIM}](scikit_eo_03.png){ width=50% }\n",
    "\n",
    "```python\n",
    "# 08 Preparing the image:\n",
    "arr = fusion.get('Fused_images')\n",
    "\n",
    "def stretch_percentiles(arr):\n",
    "    p10 = np.percentile(arr, 10) # percentile10\n",
    "    p90 = np.percentile(arr, 90) # percentile90\n",
    "    clipped_arr = np.clip(arr, p10, p90)\n",
    "    img = (clipped_arr - p10)/(p90 - p10)\n",
    "    return img\n",
    "\n",
    "arr_fusion = stretch_percentiles(arr)\n",
    "\n",
    "## Let´s plot\n",
    "fig, axes = plt.subplots(figsize = (8, 8))\n",
    "axes.imshow(arr_fusion[:,:,0:3])\n",
    "axes.set_title(\"Fusion of optical and radar images\")\n",
    "axes.grid(False)\n",
    "```\n",
    "\n",
    "![Fusion of optical and radar images. \\label{fig:AIM}](scikit_eo_04.png){ width=30% }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677550e8",
   "metadata": {},
   "source": [
    "### Example 04\n",
    "\n",
    "In this final example, the assessing accuracy and area estimate will be obtained following guidance proposed by Olofsson et al. (2014). All that we need is both the confusion matrix and a previously obtained predicted class map.\n",
    "\n",
    "Paramaters:\n",
    "\n",
    "- *matrix*: confusion matrix or error matrix in numpy.ndarray.\n",
    "- *image_pred*: Array with 2d (rows, cols). This array should be the image classified with predicted classes.\n",
    "- *pixel_size*: Pixel size of the image classified. By default is 10m of Sentinel-2. In this case is 30m (Landsat).\n",
    "- *conf*: Confidence interval. By default is 95% (1.96).\n",
    "- *nodata*: Nodata must be specified as 0, NaN or other any value. Keep in mind with this parameter.\n",
    "\n",
    "```python\n",
    "# 01 \n",
    "path_raster = r\"C:\\data\\ml\\predicted_map.tif\"\n",
    "img = rasterio.open(path_optical).read(1)\n",
    "\n",
    "path_cm = r\"C:\\data\\ml\\confusion_matrix.csv\"\n",
    "values = pd.read_csv(path_radar)\n",
    "\n",
    "# 02 Applying the confintervalML:\n",
    "confintervalML(matrix = values, image_pred = img, pixel_size = 30, conf = 1.96, nodata = -9999)\n",
    "```\n",
    "Results:\n",
    "\n",
    "![Contributions. \\label{fig:AIM}](scikit_eo_05.png){ width=30% }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb066a3",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "\n",
    "The authors would like to thank to David Montero Loaiza for the idea of the package name and Qiusheng Wu for the suggestions that helped to improve the package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
